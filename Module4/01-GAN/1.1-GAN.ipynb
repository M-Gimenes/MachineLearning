{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregando dígitos MNIST:\n",
    "from keras.datasets.mnist import load_data\n",
    "(digitos_treino, classes_treino), (digitos_teste, classes_teste) = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Versão do TensorFlow: 2.17.0\n",
      "GPUs disponíveis: []\n",
      "Keras está rodando na CPU.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "print(\"Versão do TensorFlow:\", tf.__version__)\n",
    "print(\"GPUs disponíveis:\", tf.config.list_physical_devices('GPU'))\n",
    "\n",
    "# Verifica se o TensorFlow está realmente usando a GPU\n",
    "if tf.config.list_physical_devices('GPU'):\n",
    "    print(\"Keras está rodando na GPU!\")\n",
    "else:\n",
    "    print(\"Keras está rodando na CPU.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x1000 with 16 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Conferindo o dataset coletado:\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "for i in range(16):\n",
    "    plt.subplot(4, 4, i+1)\n",
    "    plt.imshow(digitos_treino[i], cmap='gray')\n",
    "    plt.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60000"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "digitos_treino.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Flatten, Reshape\n",
    "from keras.layers import Conv2D, Conv2DTranspose, UpSampling2D\n",
    "from keras.layers import LeakyReLU, Dropout\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.optimizers import Adam, RMSprop\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "altura = digitos_treino.shape[1]  \n",
    "largura = digitos_treino.shape[2]\n",
    "num_channels = 1  # imagens grayscale\n",
    "\n",
    "digitos_treino = digitos_treino/127.5 - 1.0\n",
    "\n",
    "# Adicionando uma dimensão extra de profundidade (de tamanho 1, grayscale):\n",
    "x_treino = np.reshape(digitos_treino, (digitos_treino.shape[0], altura, largura, num_channels))\n",
    "\n",
    "# Normalizando os dados:\n",
    "x_treino = x_treino.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando a classe de modelos Deep Convolutional GAN:\n",
    "class Modelos_DCGAN(object):\n",
    "    def __init__(self, altura=28, largura=28, channels=1):\n",
    "\n",
    "        self.altura = altura\n",
    "        self.largura = largura\n",
    "        self.channels = channels\n",
    "        self.esqueleto_D = None  # discriminator \n",
    "        self.esqueleto_G = None # generator\n",
    "        self.modelo_A = None  # adversarial\n",
    "        self.modelo_D = None # discriminator\n",
    "\n",
    "    def esqueleto_discriminator(self):\n",
    "        if self.esqueleto_D: # se já foi criado uma vez, não precisa criar de novo\n",
    "            return self.esqueleto_D\n",
    "        \n",
    "        # Criando o esqueleto da CNN Discriminator:\n",
    "        self.esqueleto_D = Sequential()\n",
    "        dropout = 0.4\n",
    "\n",
    "        input_shape = (self.altura, self.largura, self.channels)\n",
    "        self.esqueleto_D.add(Conv2D(filters=64, kernel_size=5, strides=2, input_shape=input_shape, padding='same'))\n",
    "        self.esqueleto_D.add(LeakyReLU(alpha=0.2)) # o paper original de 2013 usa Relu, mas alguns papers mais modernos dizem que LeakyRelu funcionou melhor empiricamente, especialmente com imagens de maior resolução\n",
    "        self.esqueleto_D.add(Dropout(dropout))\n",
    "\n",
    "        self.esqueleto_D.add(Conv2D(filters=128, kernel_size=5, strides=2, padding='same'))\n",
    "        self.esqueleto_D.add(LeakyReLU(alpha=0.2))\n",
    "        self.esqueleto_D.add(Dropout(dropout))\n",
    "\n",
    "        self.esqueleto_D.add(Conv2D(filters=256, kernel_size=5, strides=2, padding='same'))\n",
    "        self.esqueleto_D.add(LeakyReLU(alpha=0.2))\n",
    "        self.esqueleto_D.add(Dropout(dropout))\n",
    "\n",
    "        self.esqueleto_D.add(Conv2D(filters=512, kernel_size=5, strides=1, padding='same'))\n",
    "        self.esqueleto_D.add(LeakyReLU(alpha=0.2))\n",
    "        self.esqueleto_D.add(Dropout(dropout))\n",
    "\n",
    "        self.esqueleto_D.add(Flatten())\n",
    "        self.esqueleto_D.add(Dense(1))\n",
    "        self.esqueleto_D.add(Activation('sigmoid'))\n",
    "        return self.esqueleto_D\n",
    "\n",
    "    def esqueleto_generator(self):\n",
    "        if self.esqueleto_G:\n",
    "            return self.esqueleto_G\n",
    "        self.esqueleto_G = Sequential()\n",
    "        dropout = 0.4\n",
    "        profundidade = 256\n",
    "        lado = 7\n",
    "        \n",
    "        # O objetivo é finalizar tudo com uma dimensão de 28 x 28 x 1\n",
    "        # Primeiro criaremos um vetor de neurônios cujo tamanho permita fazer um reshape de saída de 7 x 7 x 256\n",
    "        self.esqueleto_G.add(Dense(lado*lado*profundidade, input_dim=100)) # usa-se input_dim quando a entrada é um escalar de dimensão 1. Uma alternativa seria usar input_shape=(100,)\n",
    "        self.esqueleto_G.add(BatchNormalization(momentum=0.9))\n",
    "        self.esqueleto_G.add(Activation('relu'))\n",
    "        self.esqueleto_G.add(Reshape((lado, lado, profundidade))) # a saída atual está 7 x 7 x 256\n",
    "        self.esqueleto_G.add(Dropout(dropout))\n",
    "\n",
    "        self.esqueleto_G.add(UpSampling2D(size=(2, 2))) # a saída passou a ser 14 x 14 x 256\n",
    "        self.esqueleto_G.add(Conv2DTranspose(filters=128, kernel_size=5, padding='same')) # a saída passou a ser 14 x 14 x 128 (obs: padding='same' adiciona uma camada de zeros tal que as dimensões de saída sejam iguais às de entrada)\n",
    "        self.esqueleto_G.add(BatchNormalization(momentum=0.9))\n",
    "        self.esqueleto_G.add(Activation('relu'))\n",
    "\n",
    "        self.esqueleto_G.add(UpSampling2D()) # a saída passou a ser 28 x 28 x 128\n",
    "        self.esqueleto_G.add(Conv2DTranspose(filters=64, kernel_size=5, padding='same')) # a saída passou a ser 28 x 28 x 64\n",
    "        self.esqueleto_G.add(BatchNormalization(momentum=0.9))\n",
    "        self.esqueleto_G.add(Activation('relu'))\n",
    "\n",
    "        self.esqueleto_G.add(Conv2DTranspose(filters=32, kernel_size=5, padding='same')) # a saída passou a ser 28 x 28 x 32\n",
    "        self.esqueleto_G.add(BatchNormalization(momentum=0.9))\n",
    "        self.esqueleto_G.add(Activation('relu'))\n",
    "\n",
    "        self.esqueleto_G.add(Conv2DTranspose(filters=1, kernel_size=5, padding='same')) # a saída passou a ser 28 x 28 x 1\n",
    "        self.esqueleto_G.add(Activation('tanh')) # cada pixel de saída ficará entre o range (0, 1)\n",
    "        return self.esqueleto_G\n",
    "\n",
    "    def modelo_discriminator(self): # adiciona o otimizador e a função de custo a partir do esqueleto discriminador já montado\n",
    "        if self.modelo_D:\n",
    "            return self.modelo_D\n",
    "        optimizer = RMSprop(learning_rate=0.0002, decay=6e-8)\n",
    "        self.modelo_D = Sequential()\n",
    "        self.modelo_D.add(self.esqueleto_discriminator())\n",
    "        self.modelo_D.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "        return self.modelo_D # Modelo Discriminator pronto, recebe uma entrada 28 x 28 x 1 e retorna uma prob. entre 0 e 1\n",
    "\n",
    "    def modelo_adversarial(self): # adiciona o otimizador e a função de custo a partir dos esqueletos generator e discriminator\n",
    "        if self.modelo_A:\n",
    "            return self.modelo_A\n",
    "        optimizer = RMSprop(learning_rate=0.0001, decay=3e-8)\n",
    "        self.modelo_A = Sequential()\n",
    "        self.modelo_A.add(self.esqueleto_generator())\n",
    "        self.modelo_A.add(self.esqueleto_discriminator())\n",
    "        self.modelo_A.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "        return self.modelo_A\n",
    "\n",
    "# Criando a classe DCGAN completa:\n",
    "class DCGAN(object):\n",
    "    def __init__(self, altura=28, largura=28, channels=1, x_treino=None):\n",
    "        self.altura = altura\n",
    "        self.largura = largura\n",
    "        self.channels = channels\n",
    "\n",
    "        self.x_treino = x_treino\n",
    "\n",
    "        self.modelos_DCGAN = Modelos_DCGAN(altura=altura, largura=largura, channels=channels)\n",
    "        self.discriminator =  self.modelos_DCGAN.modelo_discriminator()\n",
    "        self.adversarial = self.modelos_DCGAN.modelo_adversarial()\n",
    "        self.generator = self.modelos_DCGAN.esqueleto_generator()\n",
    "        \n",
    "    # Função que congela os pesos do discriminator durante o treinamento:\n",
    "    def discriminator_trainable(self, val): # recebe True ou False\n",
    "        self.discriminator.trainable = val\n",
    "        for l in self.discriminator.layers:\n",
    "            l.trainable = val\n",
    "\n",
    "    # Função que realiza os treinamentos de ambos os modelos:\n",
    "    def train(self, train_steps=5000, batch_size=250, intervalo_mostra_imagens=1000):\n",
    "\n",
    "        for i in range(train_steps):\n",
    "            imagens_reais = self.x_treino[np.random.randint(0, self.x_treino.shape[0], size=batch_size), :, :, :] # selecionando aleatoriamente imagens de x_treino, uma quantidade batch_size de imagens\n",
    "            ruidos = np.random.uniform(-1.0, 1.0, size=[batch_size, 100]) # criando uma quantidade batch_size de ruídos\n",
    "            imagens_fake = self.generator.predict(ruidos) # passando cada um desses ruídos pelo modelo generator para criar as imagens fake\n",
    "            x = np.concatenate((imagens_reais, imagens_fake)) # agrupando ambas as imagens reais e fake em uma única variável\n",
    "            \n",
    "            # Criando um vetor y do tamanho de x com 1's e 0's (as imagens reais serão marcadas com 1 e as fake com 0):\n",
    "            y = np.ones([2*batch_size, 1])  \n",
    "            y[batch_size:, :] = 0\n",
    "            \n",
    "            # Treinando a rede discriminadora e coletando seu loss atual:\n",
    "            self.discriminator_trainable(True)\n",
    "            loss_discriminator = self.discriminator.train_on_batch(x, y) # treina a rede discriminadora no conjunto de dados informado, retornando o loss\n",
    "\n",
    "            # Treinando a rede adversarial e coletando seu loss atual:\n",
    "            y = np.ones([batch_size, 1])\n",
    "            ruidos = np.random.uniform(-1.0, 1.0, size=[batch_size, 100])\n",
    "            self.discriminator_trainable(False)\n",
    "            loss_adversarial = self.adversarial.train_on_batch(ruidos, y)\n",
    "            \n",
    "            # Mostrando na tela a evolução do treinamento (loss e acurácia de ambos os modelos):\n",
    "            if i%100==0:    \n",
    "                print('%d: [Discriminator loss: %f, acc: %f]   [Adversarial loss: %f, acc: %f]'  % (i, loss_discriminator[0], \n",
    "                                                                                                loss_discriminator[1], \n",
    "                                                                                                loss_adversarial[0], \n",
    "                                                                                                loss_adversarial[1]))\n",
    "            # Mostrando na tela algumas imagens fake geradas:\n",
    "            if (i+1)%intervalo_mostra_imagens==0:\n",
    "                ruido_de_entrada = np.random.uniform(-1.0, 1.0, size=[16, 100]) # criando num_amostras de ruído para mostrar na tela\n",
    "                self.plot_images(num_amostras=ruido_de_entrada.shape[0], noise=ruido_de_entrada)\n",
    "\n",
    "    # Função que plota imagens reais ou fake na tela:\n",
    "    def plot_images(self, fake=True, num_amostras=16, noise=None):\n",
    "        if fake: # se quer mostrar imagens fake geradas:\n",
    "            if noise is None:\n",
    "                noise = np.random.uniform(-1.0, 1.0, size=[num_amostras, 100])\n",
    "            imagens = self.generator.predict(noise)\n",
    "        else: # se quer mostrar imagens reais, mostre aleatoriamente num_amostras imagens reais de x_treino:\n",
    "            i = np.random.randint(0, self.x_treino.shape[0], num_amostras)\n",
    "            imagens = self.x_treino[i, :, :, :]\n",
    "\n",
    "        # Mostrando as imagens com subplot:\n",
    "        plt.figure(figsize=(10,10))\n",
    "        for i in range(imagens.shape[0]):\n",
    "            plt.subplot(4, 4, i+1)\n",
    "            imagem = imagens[i, :, :, :]\n",
    "            imagem = np.reshape(imagem, [self.altura, self.largura]) # coloca a imagem em duas dimensões somente\n",
    "            imagem = (imagem+1)*127.5\n",
    "            plt.imshow(imagem, cmap='gray')\n",
    "            plt.axis('off')\n",
    "        plt.tight_layout()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Matheus\\Desktop\\Matheus\\Programming\\Python\\MachineLearning\\venv\\Lib\\site-packages\\keras\\src\\optimizers\\base_optimizer.py:33: UserWarning: Argument `decay` is no longer supported and will be ignored.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Matheus\\Desktop\\Matheus\\Programming\\Python\\MachineLearning\\venv\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "c:\\Users\\Matheus\\Desktop\\Matheus\\Programming\\Python\\MachineLearning\\venv\\Lib\\site-packages\\keras\\src\\layers\\activations\\leaky_relu.py:41: UserWarning: Argument `alpha` is deprecated. Use `negative_slope` instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Matheus\\Desktop\\Matheus\\Programming\\Python\\MachineLearning\\venv\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step\n",
      "0: [Discriminator loss: 0.698149, acc: 0.488281]   [Adversarial loss: 0.601221, acc: 1.000000]\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function TensorFlowTrainer.make_train_function.<locals>.one_step_on_iterator at 0x000002C9A0BBFD80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function TensorFlowTrainer.make_train_function.<locals>.one_step_on_iterator at 0x000002C9A16671A0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 65ms/step\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Rodando o modelo:\u001b[39;00m\n\u001b[0;32m      3\u001b[0m gan \u001b[38;5;241m=\u001b[39m DCGAN(altura\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m28\u001b[39m, largura\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m28\u001b[39m, channels\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, x_treino\u001b[38;5;241m=\u001b[39mx_treino) \u001b[38;5;66;03m# instanciando a classe\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m \u001b[43mgan\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m256\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mintervalo_mostra_imagens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# treinando\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[11], line 137\u001b[0m, in \u001b[0;36mDCGAN.train\u001b[1;34m(self, train_steps, batch_size, intervalo_mostra_imagens)\u001b[0m\n\u001b[0;32m    135\u001b[0m ruidos \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39muniform(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1.0\u001b[39m, \u001b[38;5;241m1.0\u001b[39m, size\u001b[38;5;241m=\u001b[39m[batch_size, \u001b[38;5;241m100\u001b[39m])\n\u001b[0;32m    136\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdiscriminator_trainable(\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m--> 137\u001b[0m loss_adversarial \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madversarial\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_on_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mruidos\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    139\u001b[0m \u001b[38;5;66;03m# Mostrando na tela a evolução do treinamento (loss e acurácia de ambos os modelos):\u001b[39;00m\n\u001b[0;32m    140\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m i\u001b[38;5;241m%\u001b[39m\u001b[38;5;241m100\u001b[39m\u001b[38;5;241m==\u001b[39m\u001b[38;5;241m0\u001b[39m:    \n",
      "File \u001b[1;32mc:\\Users\\Matheus\\Desktop\\Matheus\\Programming\\Python\\MachineLearning\\venv\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:551\u001b[0m, in \u001b[0;36mTensorFlowTrainer.train_on_batch\u001b[1;34m(self, x, y, sample_weight, class_weight, return_dict)\u001b[0m\n\u001b[0;32m    548\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdata\u001b[39m():\n\u001b[0;32m    549\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m (x, y, sample_weight)\n\u001b[1;32m--> 551\u001b[0m logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    552\u001b[0m logs \u001b[38;5;241m=\u001b[39m tree\u001b[38;5;241m.\u001b[39mmap_structure(\u001b[38;5;28;01mlambda\u001b[39;00m x: np\u001b[38;5;241m.\u001b[39marray(x), logs)\n\u001b[0;32m    553\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m return_dict:\n",
      "File \u001b[1;32mc:\\Users\\Matheus\\Desktop\\Matheus\\Programming\\Python\\MachineLearning\\venv\\Lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\Matheus\\Desktop\\Matheus\\Programming\\Python\\MachineLearning\\venv\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:833\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    830\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    832\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 833\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    835\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    836\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32mc:\\Users\\Matheus\\Desktop\\Matheus\\Programming\\Python\\MachineLearning\\venv\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:878\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    875\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    876\u001b[0m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[0;32m    877\u001b[0m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[1;32m--> 878\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mtracing_compilation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    879\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_variable_creation_config\u001b[49m\n\u001b[0;32m    880\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    881\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables:\n\u001b[0;32m    882\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating variables on a non-first call to a function\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    883\u001b[0m                    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m decorated with tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Matheus\\Desktop\\Matheus\\Programming\\Python\\MachineLearning\\venv\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[1;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[0;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[1;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[0;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[0;32m    141\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Matheus\\Desktop\\Matheus\\Programming\\Python\\MachineLearning\\venv\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\concrete_function.py:1322\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[0;32m   1318\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1319\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1320\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1321\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1322\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1323\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1324\u001b[0m     args,\n\u001b[0;32m   1325\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1326\u001b[0m     executing_eagerly)\n\u001b[0;32m   1327\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32mc:\\Users\\Matheus\\Desktop\\Matheus\\Programming\\Python\\MachineLearning\\venv\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[1;34m(self, args)\u001b[0m\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m    215\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 216\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[1;32mc:\\Users\\Matheus\\Desktop\\Matheus\\Programming\\Python\\MachineLearning\\venv\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[0;32m    250\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[1;32m--> 251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[0;32m    258\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    259\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[0;32m    260\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[0;32m    261\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\Matheus\\Desktop\\Matheus\\Programming\\Python\\MachineLearning\\venv\\Lib\\site-packages\\tensorflow\\python\\eager\\context.py:1552\u001b[0m, in \u001b[0;36mContext.call_function\u001b[1;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[0;32m   1550\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[0;32m   1551\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1552\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1553\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1554\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1555\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1556\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1557\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1558\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1559\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1560\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m   1561\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1562\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1566\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[0;32m   1567\u001b[0m   )\n",
      "File \u001b[1;32mc:\\Users\\Matheus\\Desktop\\Matheus\\Programming\\Python\\MachineLearning\\venv\\Lib\\site-packages\\tensorflow\\python\\eager\\execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Rodando o modelo:\n",
    "\n",
    "gan = DCGAN(altura=28, largura=28, channels=1, x_treino=x_treino) # instanciando a classe\n",
    "gan.train(train_steps=10000, batch_size=256, intervalo_mostra_imagens=1000) # treinando"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mostrando os resultados finais:\n",
    "gan.plot_images(fake=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
